{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dec8ef23",
   "metadata": {},
   "source": [
    "# DA00_Function_Import_Main_df\n",
    "\n",
    "This notebook demonstrates the example execution of `DA00_Function_Import_Main_df.py`. We will go step by step through its functions, explaining their usage with examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda3503f",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a750d1",
   "metadata": {},
   "source": [
    "### Import multiple Neware txt files, loop until all files found, remove tab and header using skiprows, remove index and \".\" as decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeca219",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def DA00_Function_Import(data_folder,file_name,rated_capacity):\n",
    "        df_main = []\n",
    "    i = 0  # Start counter\n",
    "\n",
    "    while True:\n",
    "        file_path = f\"{data_folder}/{file_name}/{file_name}__{i}.txt\"\n",
    "        if os.path.exists(file_path):\n",
    "            dataraw = pd.read_csv(file_path, sep='\\t', skiprows=0, index_col=False, decimal='.')\n",
    "            df_main.append(dataraw)  # Append dataframe to the list\n",
    "            i += 1  # Increment counter for the next file\n",
    "        else:\n",
    "            print(f\"File {file_path} not found. Stopping.\")\n",
    "            break  # Exit loop when the file is not found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70916250",
   "metadata": {},
   "source": [
    "### Combine into one main dataframe and renaming to prevent further error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_main = pd.concat(df_main, ignore_index=True)\n",
    "    name_conversion_dict = {'Time(h:min:s.ms)': 'Time', 'Voltage(V)':'Voltage', 'Current(mA)': 'Current', 'Capacity(mAh)': 'Capacity', 'dQ/dV(mAh/V)':'dQdV'}\n",
    "    df_main = df_main.rename(columns=name_conversion_dict)\n",
    "    df_main['Realtime'] = pd.to_datetime(df_main['Realtime'], format='%m/%d/%Y %H:%M:%S')\n",
    "    df_main['Time'] = pd.to_timedelta(df_main['Time'].astype(str))\n",
    "    df_main['Cycle_Time'] = df_main.groupby('Cycle ID')['Time'].cumsum()\n",
    "    df_main['SOH'] = df_main['Capacity']/rated_capacity\n",
    "    \n",
    "    return df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59830c47",
   "metadata": {},
   "source": [
    "## Data Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629dd3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DA00_Function_df_Cycle_Grouping(df_main,result_folder,file_name):\n",
    "    #Make result folder\n",
    "    os.makedirs(f\"{result_folder}/{file_name}\", exist_ok=True)  # exist_ok=True avoids errors if the folder already exists\n",
    "    print(f\"Folder '{result_folder}/{file_name}' created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae705c",
   "metadata": {},
   "source": [
    "# Function to add CC_Chg to CV_Chg capacity (as initial capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb68b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def accumulate_capacity(df, start_capacity):\n",
    "        df['Accumulated_Capacity'] = df['Capacity'] + start_capacity\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56457353",
   "metadata": {},
   "source": [
    "# Grouping dataframe by Cycle ID, cycle_id = the cycle numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5441f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_cycle_grouped = df_main.groupby('Cycle ID')\n",
    "    cycle_id = df_cycle_grouped.groups.keys()\n",
    "    ## Initialize an empty list to store data for each cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b4f110",
   "metadata": {},
   "source": [
    "### Group by Step Name within each cycle & Iterate over each cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_VQ_grouped_list = []\n",
    "    for cycle_id, df_cyc in df_cycle_grouped:\n",
    "        df_step_grouped = df_cyc.groupby('Step Name')\n",
    "        step_group_name = df_step_grouped.groups.keys()\n",
    "       \n",
    "        if 'CC_Chg' and 'CV_Chg' and 'CC_DChg' in step_group_name:\n",
    "            cc_chg = df_step_grouped.get_group('CC_Chg') if 'CC_Chg' in df_step_grouped.groups else pd.DataFrame()\n",
    "            cv_chg = df_step_grouped.get_group('CV_Chg') if 'CV_Chg' in df_step_grouped.groups else pd.DataFrame()\n",
    "            cc_dchg = df_step_grouped.get_group('CC_DChg') if 'CC_DChg' in df_step_grouped.groups else pd.DataFrame()\n",
    "            vchg = pd.concat([cc_chg['Voltage'], cv_chg['Voltage']]) if not cv_chg.empty else cc_chg['Voltage']\n",
    "            dqdvchg = pd.concat([cc_chg['dQdV'], cv_chg['dQdV']]) if not cv_chg.empty else cc_chg['dQdV']\n",
    "            cchg_start = cc_chg['Capacity'].iloc[-1] if not cc_chg.empty else 0\n",
    "            cchg = pd.concat([cc_chg['Capacity'], accumulate_capacity(cv_chg, cchg_start)['Accumulated_Capacity']]) if not cv_chg.empty else   cc_chg['Capacity']\n",
    "            vdchg = cc_dchg['Voltage'] if not cc_dchg.empty else pd.Series()\n",
    "            cdchg = cc_dchg['Capacity'] if not cc_dchg.empty else pd.Series()\n",
    "            dqdvdchg = cc_dchg['dQdV'] if not cc_dchg.empty else pd.Series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724af9fa",
   "metadata": {},
   "source": [
    "### Combine into a DataFrame for V-Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d819b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "            df_VQ = pd.DataFrame({\n",
    "                f'Cycle_{cycle_id}_VChg': vchg.reset_index(drop=True),\n",
    "                f'Cycle_{cycle_id}_CapChg': cchg.reset_index(drop=True),\n",
    "                f'Cycle_{cycle_id}_dQdVChg': dqdvchg.reset_index(drop=True),\n",
    "                f'Cycle_{cycle_id}_VDChg': vdchg.reset_index(drop=True),\n",
    "                f'Cycle_{cycle_id}_CapDChg': cdchg.reset_index(drop=True),\n",
    "                f'Cycle_{cycle_id}_dQdVDChg': dqdvdchg.reset_index(drop=True),\n",
    "                })\n",
    "            df_VQ_grouped_list.append(df_VQ)\n",
    "        \n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a25785c",
   "metadata": {},
   "source": [
    "### Concatenate all cycle data horizontally and save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_VQ_grouped = pd.concat(df_VQ_grouped_list, axis=1)\n",
    "    df_VQ_grouped.to_csv(f'{result_folder}/{file_name}/df_VQ_grouped_{file_name}.csv', index=False)\n",
    "\n",
    "return df_cycle_grouped,df_VQ_grouped"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
